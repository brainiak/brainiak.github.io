<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>brainiak.reconstruct package &mdash; brainiak 0.12 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="brainiak.reprsimil package" href="brainiak.reprsimil.html" />
    <link rel="prev" title="brainiak.matnormal package" href="brainiak.matnormal.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            brainiak
          </a>
              <div class="version">
                0.12
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">brainiak</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="api.html">API</a></li>
          <li class="breadcrumb-item"><a href="brainiak.html">brainiak package</a></li>
      <li class="breadcrumb-item active">brainiak.reconstruct package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/brainiak.reconstruct.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="module-brainiak.reconstruct">
<span id="brainiak-reconstruct-package"></span><h1>brainiak.reconstruct package<a class="headerlink" href="#module-brainiak.reconstruct" title="Permalink to this heading"></a></h1>
<p>Inverted encoding model for recreating continuous representations.</p>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</div>
<div class="section" id="module-brainiak.reconstruct.iem">
<span id="brainiak-reconstruct-iem-module"></span><h2>brainiak.reconstruct.iem module<a class="headerlink" href="#module-brainiak.reconstruct.iem" title="Permalink to this heading"></a></h2>
<p>Inverted Encoding Model (IEM)</p>
<p>Method to decode and reconstruct features from data.</p>
<p>The implementation is roughly based on the following publications:</p>
<p>[Kok2013] “1.Kok, P., Brouwer, G. J., Gerven, M. A. J. van &amp;
Lange, F. P. de. Prior Expectations Bias Sensory Representations
in Visual Cortex. J. Neurosci. 33, 16275–16284 (2013).</p>
<p>[Brouwer2011] “2.Brouwer, G. J. &amp; Heeger, D. J. Cross-orientation
suppression in human visual cortex. J. Neurophysiol. 106(5):
2108-2119 (2011).</p>
<p>[Brouwer2009] “3.Brouwer, G. J. &amp; Heeger, D. J.
Decoding and Reconstructing Color from Responses in Human Visual
Cortex. J. Neurosci. 29, 13992–14003 (2009).</p>
<p>This implementation uses a set of sinusoidal
basis functions to represent the set of possible feature values.
A feature value is some characteristic of a stimulus, e.g. the
angular location of a target along a horizontal line. This code was
written to give some flexibility compared to the specific instances
in Kok, 2013 &amp; in Brouwer, 2009. Users can set the number of basis
functions, or channels, and the range of possible feature values.</p>
<p>There are separate classes for reconstructing feature values in a
1-dimensional (1D) space or in a 2-dimensional (2D) space.</p>
<dl class="py class">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">brainiak.reconstruct.iem.</span></span><span class="sig-name descname"><span class="pre">InvertedEncoding1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_exp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stimulus_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'halfcircular'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">range_stop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">180.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_density</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">180</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stimulus_resolution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></p>
<p>Basis function-based reconstruction method</p>
<p>Inverted encoding models (alternatively known as forward models) are used
to reconstruct a feature represented in some N-dimensional space, here 1D,
(e.g. color of a stimulus) from patterns across voxels in functional data.
The model uses n_channels number of idealized basis functions and assumes
that the transformation from stimulus feature (e.g. color) to basis
function is one- to-one and invertible. The response of a voxel is
expressed as the weighted sum of basis functions. In this implementation,
basis functions were half-wave rectified sinusoid functions raised to a
power set by the user (e.g. 6).</p>
<p>The model:
Inverted encoding models reconstruct a stimulus feature from
patterns of BOLD activity by relating the activity in each
voxel, B, to the values of hypothetical channels (or basis
functions), C, according to Equation 1 below.</p>
<ol class="arabic simple">
<li><p>B = W*C</p></li>
</ol>
<p>where W is a weight matrix that represents the relationship
between BOLD activity and Channels. W must be estimated from
training data; this implementation (and most described in the
literature) uses linear regression to estimate W as in Equation
2 below [note: inv() represents matrix inverse or
pseudo-inverse].</p>
<ol class="arabic simple" start="2">
<li><p>W_est = B_train*inv(C_train)</p></li>
</ol>
<p>The weights in W_est (short for “estimated”) represent the
contributions of each channel to the response of each voxel.
Estimated channel responses can be computed given W_est and
new voxel activity represented in matrix B_exp (short for
“experiment”) through inversion of Equation 1:</p>
<ol class="arabic simple" start="3">
<li><p>C_est = inv(W_est)*B_exp</p></li>
</ol>
<p>Given estimated channel responses, C_est, it is straightforward
to obtain the reconstructed feature value by summing over
channels multiplied by their channel responses and taking the
argmax (i.e. the feature associated with the maximum value).</p>
<p>Using this model:
Use fit() to estimate the weights of the basis functions given
input data (e.g. beta values from fMRI data). This function
will execute equation 2 above.</p>
<p>Use predict() to compute predicted stimulus values
from new functional data. This function computes estimated
channel responses, as in equation 3, then computes summed
channel output and finds the argmax (within the stimulus
feature space) associated with those responses.</p>
<p>Use score() to compute a measure of the error of the prediction
based on known stimuli.</p>
<p>This implementation assumes a circular (or half-
circular) feature domain. Future implementations might
generalize the feature input space, and increase the
possible dimensionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_channels</strong> (<em>int</em><em>, </em><em>default 5. Number</em><em> of </em><em>channels</em>) – The number of channels, or basis functions, to be used in
the inverted encoding model.</p></li>
<li><p><strong>channel_exp</strong> (<em>int</em><em>, </em><em>default 6. Basis function exponent.</em>) – The exponent of the sinuoidal basis functions, which
establishes the width of the functions.</p></li>
<li><p><strong>stimulus_mode</strong> (<em>str</em><em>, </em><em>default 'halfcircular'</em><em> (</em><em>other option is</em>) – ‘circular’). Describes the feature domain.</p></li>
<li><p><strong>range_start</strong> (<em>double</em><em>, </em><em>default 0. Lowest value</em><em> of </em><em>domain.</em>) – Beginning value of range of independent variable
(usually degrees).</p></li>
<li><p><strong>range_stop</strong> (<em>double</em><em>, </em><em>default 180. Highest value</em><em> of </em><em>domain.</em>) – Ending value of range of independent variable
(usually degrees).</p></li>
<li><p><strong>channel_density</strong> (<em>int</em><em>, </em><em>default 180. Number</em><em> of </em><em>points in the</em>) – feature domain.</p></li>
<li><p><strong>stimulus_resolution</strong> (<em>double</em><em>, </em><em>default None will set the stimulus</em>) – resolution to be identical to the channel density. This sets
the resolution at which the stimuli were presented (e.g. a
spatial position with some width has a lower stimulus
resolution).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.channels_">
<span class="sig-name descname"><span class="pre">channels_</span></span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.channels_" title="Permalink to this definition"></a></dt>
<dd><p>matrix defining channel values</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>[n_channels, channel density] NumPy 2D array</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.W_">
<span class="sig-name descname"><span class="pre">W_</span></span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.W_" title="Permalink to this definition"></a></dt>
<dd><p>relates estimated channel responses to response amplitude
data</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>sklearn.linear_model model containing weight matrix that</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">See</span> <span class="pre">get_params()</span> <span class="pre">for</span> <span class="pre">the</span> <span class="pre">rest</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">attributes.</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.fit" title="Permalink to this definition"></a></dt>
<dd><p>Use data and feature variable labels to fit an IEM</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation data.</em><em> [</em><em>observations</em><em>, </em><em>voxels</em><em>]</em>) – Should contain the beta values for each observation or
trial and each voxel of training data.</p></li>
<li><p><strong>y</strong> (<em>numpy array</em><em> of </em><em>response variable.</em><em> [</em><em>observations</em><em>]</em>) – Should contain the feature for each observation in X.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>params</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>parameter of this object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.predict" title="Permalink to this definition"></a></dt>
<dd><p>Use test data to predict the feature</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation from test trials</em>) – </p></li>
<li><p><strong>[</strong><strong>observations</strong> – </p></li>
<li><p><strong>feature</strong> (<em>voxels</em><em>]</em><em>. Used to predict</em>) – </p></li>
<li><p><strong>observation.</strong> (<em>associated with the given</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>model_prediction</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of estimated feature values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.score" title="Permalink to this definition"></a></dt>
<dd><p>Calculate error measure of prediction. Default measurement
is R^2, the coefficient of determination.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation from new data</em>) – [observations,voxels]</p></li>
<li><p><strong>y</strong> (<em>numpy array</em><em> of </em><em>responses.</em><em> [</em><em>observations</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score_value</strong> – feature and predicted features.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>the error measurement between the actual</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding1D.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding1D.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Sets model parameters after initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>structure with parameters and change values</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">brainiak.reconstruct.iem.</span></span><span class="sig-name descname"><span class="pre">InvertedEncoding2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stim_xlim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stim_ylim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stimulus_resolution</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stim_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chan_xlim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chan_ylim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_exp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">7</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEstimator</span></code></p>
<p>Basis function-based reconstruction method</p>
<p>Inverted encoding models (alternatively known as forward models) are used
to reconstruct a feature represented in a N-dimensional space, here 2D,
(e.g. position on a projector screen) from patterns across voxels in
functional data. The model uses some number of idealized basis functions
that cover the 2D space, and assumes that the transformation from
stimulus feature (e.g. 2D spatial position) to basis function is one-
to-one and invertible. The response of a voxel is expressed as the
weighted sum of basis functions. In this implementation, basis functions
were half-wave rectified sinusoid functions raised to some power (set by
the user).</p>
<p>The documentation will refer to the ‘stimulus space’ or ‘stimulus domain’,
which should be a 2D space in consistent units (e.g. screen pixels,
or degrees visual angle). The stimulus space is the domain in which the
stimulus is reconstructed. We will refer to the each point in this 2D
stimulus domain as a ‘pixel’.</p>
<p>The model:
Inverted encoding models reconstruct a stimulus feature from
patterns of BOLD activity by relating the activity in each
voxel, B, to the values of hypothetical channels (or basis
functions), C, according to Equation 1 below.</p>
<ol class="arabic simple">
<li><p>B = W*C</p></li>
</ol>
<p>where W is a weight matrix that represents the relationship
between BOLD activity and Channels. W must be estimated from
training data; this implementation (and most described in the
literature) uses linear regression to estimate W as in Equation
2 below [note: inv() represents matrix inverse or
pseudo-inverse].</p>
<ol class="arabic simple" start="2">
<li><p>W_est = B_train*inv(C_train)</p></li>
</ol>
<p>The weights in W_est (short for “estimated”) represent the
contributions of each channel to the response of each voxel.
Estimated channel responses can be computed given W_est and
new voxel activity represented in matrix B_exp (short for
“experiment”) through inversion of Equation 1:</p>
<ol class="arabic simple" start="3">
<li><p>C_est = inv(W_est)*B_exp</p></li>
</ol>
<p>Given estimated channel responses, C_est, it is straightforward
to obtain the reconstructed feature value by summing over
channels multiplied by their channel responses and taking the
argmax (i.e. the feature associated with the maximum value).</p>
<p>Using this model:
Use fit() to estimate the weights of the basis functions given
input data (e.g. beta values from fMRI data). This function
will execute equation 2 above.</p>
<p>Use predict() to compute predicted stimulus values
from new functional data. This function computes estimated
channel responses, as in equation 3, then computes summed
channel output and finds the argmax (within the stimulus
feature space) associated with those responses.</p>
<p>Use score() to compute a measure of the error of the prediction
based on known stimuli.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stim_xlim</strong> (<em>list</em><em> of </em><em>2 floats Specifies the minimum and maximum x-values</em>) – of the area to be reconstructed. In order to be estimated properly, a
stimulus must appear at these limits. Specifying limits outside the
range of the stimuli can lead to spurious estimates.</p></li>
<li><p><strong>stim_ylim</strong> (<em>list</em><em> of </em><em>2 floats Specifies the minimum and maximum y-values</em>) – of the area to be reconstructed. In order to be estimated properly, a
stimulus must appear at these limits. Specifying limits outside the
range of the stimuli can lead to spurious estimates.</p></li>
<li><p><strong>stimulus_resolution</strong> (<em>float</em><em> or </em><em>list</em><em> of </em><em>2 floats. If a single float is</em>) – given, it will be expanded to a list (i.e. we will assume that the
reconstructed area is composed of square pixels).</p></li>
<li><p><strong>stim_radius</strong> (<em>float</em><em>, or </em><em>sequence</em><em> of </em><em>floats</em><em> [</em><em>n_stim</em><em>]</em><em>, </em><em>default None. If the</em>) – user does not define the design matrix of the encoding model (e.g. C
in B = W*C), it will be defined automatically on the assumption that
each observation was for a 2D circular stimulus of some radius.</p></li>
<li><p><strong>chan_xlim</strong> (<em>list</em><em> of </em><em>2 floats</em><em>, </em><em>default None. Specifies the minimum and</em>) – maximum x-values of the channels, or basis functions.</p></li>
<li><p><strong>chan_ylim</strong> (<em>list</em><em> of </em><em>2 floats</em><em>, </em><em>default None. Specifies the minimum and</em>) – maximum y-values of the channels, or basis functions.</p></li>
<li><p><strong>channels</strong> (<em>[</em><em>n_channels</em><em>, </em><em>n_pixels</em><em>] </em><em>NumPy 2D array</em><em>, </em><em>default None. If None at</em>) – initialization, it can be defined with
either define_basis_functions_sqgrid() or
define_basis_functions_trigrid(), each of which tiles the given 2D
space with some grid (square or triangular/hexagonal, respectively).
Alternatively, the user can specify their own channels.</p></li>
<li><p><strong>channel_exp</strong> (<em>int</em><em>, </em><em>default 7. Basis function exponent. The exponent</em><em> of </em><em>the</em>) – sinuoidal basis functions, which helps control their width.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.channels">
<span class="sig-name descname"><span class="pre">channels</span></span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.channels" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>[n_channels, n_pixels] NumPy 2D array defining channels</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.W_">
<span class="sig-name descname"><span class="pre">W_</span></span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.W_" title="Permalink to this definition"></a></dt>
<dd><p>channel responses to response data</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>sklearn.linear_model containing weight matrix that relates estimated</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">See</span> <span class="pre">get_params()</span> <span class="pre">for</span> <span class="pre">the</span> <span class="pre">rest</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">attributes.</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.define_basis_functions_sqgrid">
<span class="sig-name descname"><span class="pre">define_basis_functions_sqgrid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nchannels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.define_basis_functions_sqgrid" title="Permalink to this definition"></a></dt>
<dd><p>Define basis functions (aka channels) arrange in a square grid.
Sets the self.channels parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nchannels</strong> (<em>number</em><em> of </em><em>channels in the x</em><em> (</em><em>horizontal</em><em>) </em><em>direction</em>) – </p></li>
<li><p><strong>channel_size</strong> (<em>the desired full-width half-maximum</em><em> (</em><em>FWHM</em><em>) of </em><em>the</em>) – channel, in stimulus space.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>self.channels</strong> (<em>defines channels, a [nchannels, npixels] matrix.</em>)</p></li>
<li><p><strong>channel_centers</strong> (<em>numpy array of the centers of each channel, given as</em>) – [nchannels x 2] matrix</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.define_basis_functions_trigrid">
<span class="sig-name descname"><span class="pre">define_basis_functions_trigrid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grid_radius</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.define_basis_functions_trigrid" title="Permalink to this definition"></a></dt>
<dd><p>Define basis functions (aka channels) arranged in a triangular grid.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>self.channels</strong> (<em>defines channels, [nchannels, npixels] matrix.</em>)</p></li>
<li><p><strong>channel_centers</strong> (<em>numpy array of the centers of each channel</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.fit" title="Permalink to this definition"></a></dt>
<dd><p>Use data and feature variable labels to fit an IEM</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation data.</em><em> [</em><em>observations</em><em>, </em><em>voxels</em><em>]</em>) – Should contain the beta values for each observation or
trial and each voxel of training data.</p></li>
<li><p><strong>y</strong> (<em>numpy array</em><em> of </em><em>response variable.</em><em> [</em><em>observations</em><em>]</em>) – Should contain the feature for each observation in X.</p></li>
<li><p><strong>C</strong> (<em>numpy matrix</em><em> of </em><em>channel activations for every observation</em><em> (</em><em>e.g.</em>) – the design matrix C in the linear equation B = W*C), matrix size
[observations, pixels]. If None (default), this assumes that each
observation contains a 2D circular stimulus and will define the
activations with self._define_trial_activations(y).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.get_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>params</strong></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>parameter of this object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.predict" title="Permalink to this definition"></a></dt>
<dd><p>Use test data to predict the feature</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation from test trials</em><em> [</em><em>observations</em><em>,</em>) – voxels]. Used to predict feature associated with the given
observation.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>model_prediction</strong></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of estimated feature values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.predict_feature_responses">
<span class="sig-name descname"><span class="pre">predict_feature_responses</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.predict_feature_responses" title="Permalink to this definition"></a></dt>
<dd><p>Takes channel weights and transforms them into continuous
functions defined in the feature domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>data.</em><em> [</em><em>observations</em><em>, </em><em>voxels</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>pred_response</strong> – reconstruction in the channel domain. [pixels, observations]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>predict response from all channels. This is the stimulus</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.score" title="Permalink to this definition"></a></dt>
<dd><p>Calculate error measure of prediction, assuming that the predicted
feature is at the maximum of the reconstructed values.</p>
<p>To score the reconstructions against expected features defined in the
stimulus domain (i.e. in pixels), see score_against_reconstructed().</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation from new data</em>) – [observations,voxels]</p></li>
<li><p><strong>y</strong> (<em>numpy array</em><em> of </em><em>stimulus features.</em><em> [</em><em>observations</em><em>, </em><em>2</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score_value</strong> – feature and predicted features, [observations].</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>the error measurement between the actual</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.score_against_reconstructed">
<span class="sig-name descname"><span class="pre">score_against_reconstructed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'euclidean'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.score_against_reconstructed" title="Permalink to this definition"></a></dt>
<dd><p>Calculates a distance metric between reconstructed features in
the 2D stimulus domain (i.e. reconstructions in pixels) given
some observations X, and expected features y. Expected features must
also be in the pixel stimulus domain.</p>
<p>To score the reconstructions against the expected maxima, see score().</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em><em> of </em><em>voxel activation from new data</em>) – [observations, voxels]</p></li>
<li><p><strong>y</strong> (<em>numpy array</em><em> of </em><em>the expected stimulus reconstruction values</em><em> [</em><em>pixels</em><em>,</em>) – observations].</p></li>
<li><p><strong>metric</strong> (<em>string specifying the distance metric</em><em>, </em><em>either &quot;euclidean&quot; or</em>) – “cosine”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>score_value</strong> – values as the expected values, [observations].</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>the error measurement between the reconstructed feature</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.set_fit_request">
<span class="sig-name descname"><span class="pre">set_fit_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'$UNCHANGED$'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#brainiak.reconstruct.iem.InvertedEncoding2D" title="brainiak.reconstruct.iem.InvertedEncoding2D"><span class="pre">InvertedEncoding2D</span></a></span></span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.set_fit_request" title="Permalink to this definition"></a></dt>
<dd><p>Request metadata passed to the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<p>Note that this method is only relevant if
<code class="docutils literal notranslate"><span class="pre">enable_metadata_routing=True</span></code> (see <code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.set_config()</span></code>).
Please see <span class="xref std std-ref">User Guide</span> on how the routing
mechanism works.</p>
<p>The options for each parameter are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">True</span></code>: metadata is requested, and passed to <code class="docutils literal notranslate"><span class="pre">fit</span></code> if provided. The request is ignored if metadata is not provided.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">False</span></code>: metadata is not requested and the meta-estimator will not pass it to <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code>: metadata is not requested, and the meta-estimator will raise an error if the user provides it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">str</span></code>: metadata should be passed to the meta-estimator with this given alias instead of the original name.</p></li>
</ul>
<p>The default (<code class="docutils literal notranslate"><span class="pre">sklearn.utils.metadata_routing.UNCHANGED</span></code>) retains the
existing request. This allows you to change the request for some
parameters and not others.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.</span></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method is only relevant if this estimator is used as a
sub-estimator of a meta-estimator, e.g. used inside a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code>. Otherwise it has no effect.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>C</strong> (<em>str</em><em>, </em><em>True</em><em>, </em><em>False</em><em>, or </em><em>None</em><em>,                     </em><em>default=sklearn.utils.metadata_routing.UNCHANGED</em>) – Metadata routing for <code class="docutils literal notranslate"><span class="pre">C</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>self</strong> – The updated object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="brainiak.reconstruct.iem.InvertedEncoding2D.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">parameters</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#brainiak.reconstruct.iem.InvertedEncoding2D.set_params" title="Permalink to this definition"></a></dt>
<dd><p>Sets model parameters after initialization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>structure with parameters and change values</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="brainiak.matnormal.html" class="btn btn-neutral float-left" title="brainiak.matnormal package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="brainiak.reprsimil.html" class="btn btn-neutral float-right" title="brainiak.reprsimil package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2016, Princeton Neuroscience Institute and Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>